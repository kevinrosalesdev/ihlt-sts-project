{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Sesion exercise\n",
    "\n",
    "Develop a jupyter notebook that show the 25 non-stopwords with more number of occurrences in the file 'blake-poems.txt' of Gutenberg corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import nltk\n",
    "Natural Language Toolkit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk && stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activate only to download\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the required file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bp length: 8354, subset: ['[', 'Poems', 'by']\n"
     ]
    }
   ],
   "source": [
    "# load file\n",
    "bp = nltk.corpus.gutenberg.words('blake-poems.txt')\n",
    "print('bp length: %d, subset: %s'%(len(bp), bp[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase the file:\n",
    "It's necessary to lowercase the file, for the extraction to work properly so that for instance: the stopwords 'A' and 'a' can be later processed as equal words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bp_lower length: 8354, subset: ['[', 'poems', 'by']\n"
     ]
    }
   ],
   "source": [
    "# lowercase the file\n",
    "bp_lower = [word.lower() for word in bp]\n",
    "print('bp_lower length: %d, subset: %s'%(len(bp), bp_lower[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords length: 179, subset: ['i', 'me', 'my']\n"
     ]
    }
   ],
   "source": [
    "# read stopwords in english\n",
    "stop_words = stopwords.words('english')\n",
    "print('stopwords length: %d, subset: %s'%(len(stop_words), stop_words[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Raw' extraction of the non-stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-stopwords length: 5225, 25 ocurrences: [(',', 680), ('.', 201), (\"'\", 104), (';', 98), (':', 75), ('?', 65), ('!', 59), ('\"', 51), ('little', 45), ('thee', 42), ('thou', 35), ('like', 35), ('thy', 31), ('love', 29), ('night', 28), ('sweet', 28), ('joy', 25), ('away', 24), ('weep', 24), ('father', 22), ('sleep', 21), ('-', 20), ('.\"', 20), ('shall', 19), ('day', 19)]\n"
     ]
    }
   ],
   "source": [
    "# extract non-stopwords from file\n",
    "non_stopwords = [word for word in bp_lower if word not in stop_words]\n",
    "# frequencies of words\n",
    "freqs = {w:non_stopwords.count(w) for w in set(non_stopwords)}\n",
    "# order 25 ocurrences of non-stopwords\n",
    "ord= sorted(freqs.items(), key=lambda x:x[1], reverse=True)\n",
    "print('non-stopwords length: %d, 25 ocurrences: %s'%(len(non_stopwords), ord[:25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the file:\n",
    "To do a cleaner extraction: avoiding punctuation marks, signs and symbols, etc. We could make use of the 'Regular Expression' module from python3 **re.findall()** that returns all the matches as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the words\n",
    "\n",
    "The function **re.findall** can help us clean the file with the regex ('\\w+')\n",
    "to search for sequences of letters (not including punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new length of non-stopwords: 3807\n"
     ]
    }
   ],
   "source": [
    "# extract only the words\n",
    "# rejoin the words with space\n",
    "clean_text = ' '.join(non_stopwords)\n",
    "# filtering to get only the words\n",
    "finalnon_stopwords = re.findall('\\w+', clean_text)\n",
    "# length\n",
    "print('new length of non-stopwords: %d'%(len(finalnon_stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('little', 45),\n",
       " ('thee', 42),\n",
       " ('thou', 35),\n",
       " ('like', 35),\n",
       " ('thy', 31),\n",
       " ('love', 29),\n",
       " ('night', 28),\n",
       " ('sweet', 28),\n",
       " ('joy', 25),\n",
       " ('away', 24),\n",
       " ('weep', 24),\n",
       " ('father', 22),\n",
       " ('sleep', 21),\n",
       " ('shall', 19),\n",
       " ('day', 19),\n",
       " ('mother', 19),\n",
       " ('happy', 19),\n",
       " ('child', 18),\n",
       " ('every', 17),\n",
       " ('never', 17),\n",
       " ('human', 16),\n",
       " ('voice', 16),\n",
       " ('er', 16),\n",
       " ('infant', 16),\n",
       " ('green', 16)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequencies of words\n",
    "freqs = {w:finalnon_stopwords.count(w) for w in set(finalnon_stopwords)}\n",
    "#order 25 ocurrences of nonstop words\n",
    "ord= sorted(freqs.items(), key=lambda x:x[1], reverse=True)\n",
    "ord[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new stopwords\n",
    "The word **('er',16)** looks suspicious. With a quick check to the file 'blake-poems.txt' we see the recurrent preposition 'O'er'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"er\" exist?: True\n",
      "Displaying 16 of 16 matches:\n",
      "d bid thee feed By the stream and o ' er the mead ; Gave thee clothing of deli\n",
      " SONG Sweet dreams , form a shade O ' er my lovely infant ' s head ! Sweet dre\n",
      " Sweet Sleep , angel mild , Hover o ' er my happy child ! Sweet smiles , in th\n",
      "eep , sleep , happy sleep , While o ' er thee doth mother weep . Sweet babe , \n",
      " shine like the gold , As I guard o ' er the fold .\" SPRING Sound the flute ! \n",
      "AM Once a dream did weave a shade O ' er my angel - guarded bed , That an emme\n",
      "is eternal winter there . For where ' er the sun does shine , And where ' er t\n",
      "' er the sun does shine , And where ' er the rain does fall , Babes should nev\n",
      "p . \" Frowning , frowning night , O ' er this desert bright Let thy moon arise\n",
      " viewed : Then he gambolled round O ' er the hallowed ground . Leopards , tige\n",
      " an Angel mild : Witless woe was ne ' er beguiled ! And I wept both night and \n",
      " ,\" And I passed the sweet flower o ' er . Then I went to my pretty rose tree \n",
      " meet When the silent sleep Waves o ' er heaven ' s deep , And the weary tired\n",
      " of winter appear ? TO TERZAH Whate ' er is born of mortal birth Must be consu\n",
      "annot crave , the voiceless , the o ' er tired The breath doth nourish the inn\n",
      "hy sighs . And all thy moans flew o ' er my roof , but I have call ' d them do\n"
     ]
    }
   ],
   "source": [
    "# check if word exist\n",
    "print('\"er\" exist?: %s'%(\"er\" in bp))\n",
    "# consulting context in corpus\n",
    "from nltk.text import Text\n",
    "crp = Text(bp)\n",
    "crp.concordance('er')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could add 'er' as a stopword to make a better extraction at the begining: **stop_word.append('er')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('little', 45),\n",
       " ('thee', 42),\n",
       " ('thou', 35),\n",
       " ('like', 35),\n",
       " ('thy', 31),\n",
       " ('love', 29),\n",
       " ('night', 28),\n",
       " ('sweet', 28),\n",
       " ('joy', 25),\n",
       " ('away', 24),\n",
       " ('weep', 24),\n",
       " ('father', 22),\n",
       " ('sleep', 21),\n",
       " ('shall', 19),\n",
       " ('day', 19),\n",
       " ('mother', 19),\n",
       " ('happy', 19),\n",
       " ('child', 18),\n",
       " ('every', 17),\n",
       " ('never', 17),\n",
       " ('human', 16),\n",
       " ('voice', 16),\n",
       " ('infant', 16),\n",
       " ('green', 16),\n",
       " ('thel', 16)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# including a stopword\n",
    "stop_words.append(\"er\")\n",
    "# extract nonstop words from file\n",
    "non_stopwords = [word for word in bp_lower if word not in stop_words]\n",
    "# extract only the words\n",
    "clean_text = ' '.join(non_stopwords)\n",
    "finalnon_stopwords = re.findall('\\w+', clean_text)\n",
    "# frequencies of words\n",
    "freqs = {w:finalnon_stopwords.count(w) for w in set(finalnon_stopwords)}\n",
    "# order 25 ocurrences of nonstop words\n",
    "# it's necessary to reverse the sort to have them in descendent form\n",
    "ord= sorted(freqs.items(), key=lambda x:x[1], reverse=True)\n",
    "ord[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And there we have 25 non-stopwords with more number of occurrences in the file 'blake-poems.txt' of Gutenberg corpus.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative solution\n",
    "Aditionally there's an alternative aproach to this exercise that optimizes the process using python3 module: **Counter.**\n",
    "\n",
    "Counter is a container that keeps track of how many times equivalent values are added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the extraction again with the cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract non-stopwords from file\n",
    "alt_non_stopwords = [word for word in bp_lower if word not in stop_words]\n",
    "# extract only the words\n",
    "clean_text = ' '.join(alt_non_stopwords)\n",
    "f_words = re.findall('\\w+', clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Counter().most_common function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('little', 45),\n",
       " ('thee', 42),\n",
       " ('like', 35),\n",
       " ('thou', 35),\n",
       " ('thy', 31),\n",
       " ('love', 29),\n",
       " ('sweet', 28),\n",
       " ('night', 28),\n",
       " ('joy', 25),\n",
       " ('away', 24),\n",
       " ('weep', 24),\n",
       " ('father', 22),\n",
       " ('sleep', 21),\n",
       " ('happy', 19),\n",
       " ('shall', 19),\n",
       " ('day', 19),\n",
       " ('mother', 19),\n",
       " ('child', 18),\n",
       " ('every', 17),\n",
       " ('never', 17),\n",
       " ('thel', 16),\n",
       " ('hear', 16),\n",
       " ('green', 16),\n",
       " ('voice', 16),\n",
       " ('infant', 16)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 25 ocurrences of nonstop words\n",
    "top_25 = Counter(f_words).most_common(25)\n",
    "top_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "There seem to be multiple ways to approach a solution to a data-processing related problem. It'll be advisable to do a quick research to the problem and learn how other people have resolved it, so that the issue can be better understod and it can be provide with the simpler solution.\n",
    "\n",
    "Therefore to avoid *reinventing the wheel*, we ought to use build-in-functions from other modules whenever posible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
