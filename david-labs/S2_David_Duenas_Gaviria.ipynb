{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2 - Sesion exercise\n",
    "\n",
    " * Read all pairs of sentences of the trial set within the evaluation framework of the project.\n",
    " * Compute their similarities by considering words and Jaccard distance. A distance should be obtained for each pair of sentences (a vector of similarities).\n",
    " * Compare the previous results with gold standard by giving the pearson correlation between them. Only a global measure should be obtained from all previous distances. from scipy.stats import pearsonr pearsonr(refs, tsts)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "beautiful soup\n",
    "the jaccard distance\n",
    "and pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy.stats import pearsonr\n",
    "from nltk.metrics import jaccard_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One way to read the file could be using the BeautifulSoup module\n",
    "The b4s opens a html with the text embedded as a paragraph <body/><p/> and from there parse the info. but as this is not a html or xml it's not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>id1\tThe bird is bathing in the sink.\tBirdie is washing itself in the water basin.\n",
      "id2\tIn May 2010, the troops attempted to invade Kabul.\tThe US army invaded Kabul on May 7th last year, 2010.\n",
      "id3\tJohn said he is considered a witness but not a suspect.\t\"He is not a suspect anymore.\" John said.\n",
      "id4\tThey flew out of the nest in groups.\tThey flew into the nest together.\n",
      "id5\tThe woman is playing the violin.\tThe young lady enjoys listening to the guitar.\n",
      "id6\tJohn went horse back riding at dawn with a whole group of friends.\tSunrise at dawn is a magnificent view to take in if you wake up early enough for it.\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(open(\"STS.input.txt\"))\n",
    "# find the </p> tag\n",
    "soup=soup.find(\"p\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id1\tThe bird is bathing in the sink.\tBirdie is washing itself in the water basin.\n",
      "id2\tIn May 2010, the troops attempted to invade Kabul.\tThe US army invaded Kabul on May 7th last year, 2010.\n",
      "id3\tJohn said he is considered a witness but not a suspect.\t\"He is not a suspect anymore.\" John said.\n",
      "id4\tThey flew out of the nest in groups.\tThey flew into the nest together.\n",
      "id5\tThe woman is playing the violin.\tThe young lady enjoys listening to the guitar.\n",
      "id6\tJohn went horse back riding at dawn with a whole group of friends.\tSunrise at dawn is a magnificent view to take in if you wake up early enough for it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the import re module we can substract the <p> tags\n",
    "import re\n",
    "replaced = re.sub(\"<p[^>]*>\", \"\", soup.get_text())\n",
    "print(replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A cleaner way to get the file with propper identation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0OgiI5-0jiQK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id1': [['The', 'bird', 'is', 'bathing', 'in', 'the', 'sink', '.'], ['Birdie', 'is', 'washing', 'itself', 'in', 'the', 'water', 'basin', '.']], 'id2': [['In', 'May', '2010', ',', 'the', 'troops', 'attempted', 'to', 'invade', 'Kabul', '.'], ['The', 'US', 'army', 'invaded', 'Kabul', 'on', 'May', '7th', 'last', 'year', ',', '2010', '.']], 'id3': [['John', 'said', 'he', 'is', 'considered', 'a', 'witness', 'but', 'not', 'a', 'suspect', '.'], ['``', 'He', 'is', 'not', 'a', 'suspect', 'anymore', '.', \"''\"], ['John', 'said', '.']], 'id4': [['They', 'flew', 'out', 'of', 'the', 'nest', 'in', 'groups', '.'], ['They', 'flew', 'into', 'the', 'nest', 'together', '.']], 'id5': [['The', 'woman', 'is', 'playing', 'the', 'violin', '.'], ['The', 'young', 'lady', 'enjoys', 'listening', 'to', 'the', 'guitar', '.']], 'id6': [['John', 'went', 'horse', 'back', 'riding', 'at', 'dawn', 'with', 'a', 'whole', 'group', 'of', 'friends', '.'], ['Sunrise', 'at', 'dawn', 'is', 'a', 'magnificent', 'view', 'to', 'take', 'in', 'if', 'you', 'wake', 'up', 'early', 'enough', 'for', 'it', '.']]}\n"
     ]
    }
   ],
   "source": [
    "# Get the plain text\n",
    "file = open(\"STS.input.txt\")\n",
    "# define the placeholders\n",
    "setence_ids = []\n",
    "sentence_tokenized = {}\n",
    "# Loop to extract each id with sentences\n",
    "for i in file:\n",
    "    id = i[0:3]\n",
    "    setence_ids.append(id)\n",
    "    sentences = nltk.sent_tokenize(i[4:])\n",
    "    sentence_tokenized[id] = [nltk.word_tokenize(s) for s in sentences]\n",
    "print (sentence_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jYIfINlpjiQP",
    "outputId": "4e59b549-deff-43cf-cccc-c907658609d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the', 'sink', 'The', 'is', '.', 'bird', 'in', 'bathing'}\n",
      "{'the', 'basin', 'washing', 'itself', 'water', 'is', '.', 'Birdie', 'in'}\n",
      "{'to', 'the', 'attempted', 'troops', 'Kabul', 'In', '.', '2010', 'invade', 'May', ','}\n",
      "{'year', 'on', 'US', 'army', 'invaded', 'The', 'Kabul', '.', '2010', 'May', 'last', ',', '7th'}\n",
      "{'John', 'but', 'a', 'he', 'considered', 'witness', 'not', 'said', 'is', 'suspect', '.'}\n",
      "{'He', 'a', '``', 'not', 'is', \"''\", 'suspect', '.', 'anymore'}\n",
      "{'the', 'of', 'flew', 'out', 'nest', 'groups', '.', 'in', 'They'}\n",
      "{'the', 'flew', 'nest', 'together', '.', 'into', 'They'}\n",
      "{'violin', 'the', 'playing', 'woman', 'The', 'is', '.'}\n",
      "{'to', 'the', 'guitar', 'lady', 'The', 'young', 'listening', 'enjoys', '.'}\n",
      "{'John', 'dawn', 'of', 'a', 'at', 'whole', 'riding', 'went', 'back', 'horse', '.', 'friends', 'with', 'group'}\n",
      "{'enough', 'in', 'to', 'view', 'dawn', 'it', 'for', 'a', 'is', 'magnificent', 'if', 'wake', 'early', 'Sunrise', 'take', 'at', 'up', '.', 'you'}\n",
      "[0.6923076923076923, 0.7368421052631579, 0.6666666666666666, 0.5454545454545454, 0.7692307692307693, 0.8620689655172413]\n"
     ]
    }
   ],
   "source": [
    "# jaccard distances\n",
    "jd = []\n",
    "for id in setence_ids:\n",
    "    print(set(sentence_tokenized.get(id)[0]))\n",
    "    print(set(sentence_tokenized.get(id)[1]))\n",
    "    distance = jaccard_distance(set(sentence_tokenized.get(id)[0]),\n",
    "                           set(sentence_tokenized.get(id)[1]))\n",
    "    jd.append(distance)\n",
    "print(jd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as the thirth sentence is wrongly separated into three. We could unite them to make a better extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'He', 'is', 'not', 'a', 'suspect', 'anymore', '.', \"''\", 'John', 'said', '.']\n"
     ]
    }
   ],
   "source": [
    "## add sentence \n",
    "sentence3_2 = sentence_tokenized.get('id3')[1]\n",
    "sentence3_3 = sentence_tokenized.get('id3')[2]\n",
    "sentence3_2.extend(sentence3_3)\n",
    "print(sentence3_2)\n",
    "# Change the sentence value of the id3\n",
    "sentence_tokenized['id3'][1] = sentence3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DhWlsmuzjiQU",
    "outputId": "39da90fa-8a38-4730-c7a4-df1d65b843bf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person correlation value: 0.414377\n"
     ]
    }
   ],
   "source": [
    "# We could get the plain text with an extraction again: gs_file = open(\"STS.gs.txt\")  or we could simply create the list with the trivial values as it is not a complex file:\n",
    "# Gold standard\n",
    "gs = [0,1,2,3,4,5]\n",
    "pearson = pearsonr(gs, jd)\n",
    "#Global value\n",
    "print('Person correlation value: %f'%(pearson[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Keeping in mind that jaccard is zero when there's no intersecction. The pearson correlation coefitione might improve if the complexity of the text is lower, with less punctuations and so on.\n",
    "\n",
    "As NLP it's hard to do with respect to generalization, there is often the posibility to enhance it with the extraction process of the sentences with manual work."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
