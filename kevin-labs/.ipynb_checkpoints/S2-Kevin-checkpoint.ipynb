{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHLT - Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read all pairs of sentences of the trial set within the evaluation framework of the project.\n",
    "\n",
    "2. Compute their similarities by considering words and Jaccard distance. A distance should be obtained for each pair of sentences (a vector of similarities).\n",
    "\n",
    "3. Compare the previous results with gold standard by giving the pearson correlation between them. Only a global measure should be obtained from all previous distances.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- Read the file 00-readme.txt of the trial data set to prepare the exercise.\n",
    "\n",
    "- Justify the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "\n",
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ('The bird is bathing in the sink.', 'Birdie is washing itself in the water basin.')\n",
      "2. ('In May 2010, the troops attempted to invade Kabul.', 'The US army invaded Kabul on May 7th last year, 2010.')\n",
      "3. ('John said he is considered a witness but not a suspect.', '\"He is not a suspect anymore.\" John said.')\n",
      "4. ('They flew out of the nest in groups.', 'They flew into the nest together.')\n",
      "5. ('The woman is playing the violin.', 'The young lady enjoys listening to the guitar.')\n",
      "6. ('John went horse back riding at dawn with a whole group of friends.', 'Sunrise at dawn is a magnificent view to take in if you wake up early enough for it.')\n"
     ]
    }
   ],
   "source": [
    "pairs = list()\n",
    "with open('trial/STS.input.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = nltk.TabTokenizer().tokenize(line.strip())\n",
    "        pairs.append((line[1], line[2]))\n",
    "        \n",
    "for index, pair in enumerate(pairs):\n",
    "    print(str(index + 1) + \".\", pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, each sentence is tokenized by words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (['The', 'bird', 'is', 'bathing', 'in', 'the', 'sink', '.'], ['Birdie', 'is', 'washing', 'itself', 'in', 'the', 'water', 'basin', '.']) \n",
      "\n",
      "2. (['In', 'May', '2010', ',', 'the', 'troops', 'attempted', 'to', 'invade', 'Kabul', '.'], ['The', 'US', 'army', 'invaded', 'Kabul', 'on', 'May', '7th', 'last', 'year', ',', '2010', '.']) \n",
      "\n",
      "3. (['John', 'said', 'he', 'is', 'considered', 'a', 'witness', 'but', 'not', 'a', 'suspect', '.'], ['``', 'He', 'is', 'not', 'a', 'suspect', 'anymore', '.', \"''\", 'John', 'said', '.']) \n",
      "\n",
      "4. (['They', 'flew', 'out', 'of', 'the', 'nest', 'in', 'groups', '.'], ['They', 'flew', 'into', 'the', 'nest', 'together', '.']) \n",
      "\n",
      "5. (['The', 'woman', 'is', 'playing', 'the', 'violin', '.'], ['The', 'young', 'lady', 'enjoys', 'listening', 'to', 'the', 'guitar', '.']) \n",
      "\n",
      "6. (['John', 'went', 'horse', 'back', 'riding', 'at', 'dawn', 'with', 'a', 'whole', 'group', 'of', 'friends', '.'], ['Sunrise', 'at', 'dawn', 'is', 'a', 'magnificent', 'view', 'to', 'take', 'in', 'if', 'you', 'wake', 'up', 'early', 'enough', 'for', 'it', '.']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pairs = [(nltk.word_tokenize(p[0]), nltk.word_tokenize(p[1])) for p in pairs]\n",
    "\n",
    "for index, pair in enumerate(pairs):\n",
    "    print(str(index + 1) + \".\", pair, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Similarities computation\n",
    "\n",
    "[*Jaccard distance*](https://www.nltk.org/api/nltk.metrics.html#nltk.metrics.distance.jaccard_distance) is used in order to get the similarity between a pair of sentences.\n",
    "\n",
    "$ Similarity = 1 - Jaccard_{Distance} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities:\n",
      "\n",
      "1. 0.3076923076923077\n",
      "2. 0.26315789473684215\n",
      "3. 0.4666666666666667\n",
      "4. 0.4545454545454546\n",
      "5. 0.23076923076923073\n",
      "6. 0.13793103448275867\n"
     ]
    }
   ],
   "source": [
    "similarities = [1 - jaccard_distance(set(p[0]), set(p[1])) for p in pairs]\n",
    "\n",
    "print(\"Similarities:\\n\")\n",
    "for index, similarity in enumerate(similarities):\n",
    "    print(str(index + 1) + \".\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results comparison with gold standard\n",
    "\n",
    "Finally, similarities are compared with the gold standard to analyze the precision of the results.\n",
    "\n",
    "As the similarity between two sentences that are completely equivalent should be 1 and the similarity between two sentences that are on different topics should be 0, the reference similarities (according to `STS.gs.txt` and `00-readme.txt`) should be:\n",
    "\n",
    "`1.0, 0.8, 0.6, 0.4, 0.2, 0` or `5, 4, 3, 2, 1, 0` (proportional values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.3962389776119232\n",
      "Pearson correlation: 0.3962389776119233\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson correlation:\", pearsonr([5, 4, 3, 2, 1, 0], similarities)[0])\n",
    "print(\"Pearson correlation:\", pearsonr([1, 0.8, 0.6, 0.4, 0.2, 0], similarities)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [*Pearson correlation coefficient*](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html), the coefficient varies between -1 and +1, with 0 implying no correlation. Correlations of -1 and +1 imply an exact linear relationship.\n",
    "\n",
    "\n",
    "The reason of this low correlation between the obtained results and the correct results is that measuring the similarities of two sentences taking into account only the *Jaccard distance* of tokenized words is not enough to get the expected results.\n",
    "\n",
    "For example, in third sentence (0.47 vs 0.6 of similarity), a good result is obtained as several words are located in both sentences:\n",
    "\n",
    "1. '**John said he is** considered a witness but **not a suspect.**'\n",
    "2. '\"**He is not a suspect** anymore\". **John said.**'\n",
    "\n",
    "Other example is the fifth sentence (0.23 vs 0.2 of similarity), a good result is obtained too because only some words are located in both samples:\n",
    "\n",
    "1. '**The** woman is playing **the** violin.'\n",
    "2. '**The** young lady enjoys listening to **the** guitar.'\n",
    "\n",
    "Nevertheless, when two sentences (as first case, 0.31 vs 1 of similarity) mean the same thing but are written using other words, the use of only one technique (*Jaccard distance*) can fail:\n",
    "\n",
    "1. 'The bird **is** bathing **in the** sink.'\n",
    "2. 'Birdie **is** washing itself **in the** water basin.'\n",
    "\n",
    "Other elements, as sentiment analysis or sentence context, should be studied in order to get a higher pearson correlation coefficient between obtained results and expected results.\n",
    "\n",
    "Finally, what would be the value of the *Pearson correlation coefficient* if lower case were used in each pairs of sentences, stopwords were removed and only words were taken into consideration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "new_pairs = list()\n",
    "for pair in pairs:\n",
    "    new_pairs.append(([w.lower() for w in pair[0] if re.search(r\"\\w\", w) and w.lower() not in sw],\n",
    "                     [w.lower() for w in pair[1] if re.search(r\"\\w\", w) and w.lower() not in sw]))\n",
    "similarities = [1 - jaccard_distance(set(p[0]), set(p[1])) for p in new_pairs]\n",
    "\n",
    "for index, pair in enumerate(new_pairs):\n",
    "    print(str(index + 1) + \".\", pair, '\\n')\n",
    "\n",
    "print(\"Similarities:\\n\")\n",
    "for index, similarity in enumerate(similarities):\n",
    "    print(str(index + 1) + \".\", similarity)    \n",
    "    \n",
    "print(\"\\nPearson correlation:\", pearsonr([5, 4, 3, 2, 1, 0], similarities)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the correlation coefficient shows, it gets a worse result. Consequently, the utilization of stopwords and other elements can improve the results in these cases as they provide a structure that helps to compare sentences. Nevertheless, as it was mentioned above, other features should be analyzed to get a higher *Pearson Correlation Coefficient*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (['bird', 'bathing', 'sink'], ['birdie', 'washing', 'water', 'basin']) \n",
      "\n",
      "2. (['may', '2010', 'troops', 'attempted', 'invade', 'kabul'], ['us', 'army', 'invaded', 'kabul', 'may', '7th', 'last', 'year', '2010']) \n",
      "\n",
      "3. (['john', 'said', 'considered', 'witness', 'suspect'], ['suspect', 'anymore', 'john', 'said']) \n",
      "\n",
      "4. (['flew', 'nest', 'groups'], ['flew', 'nest', 'together']) \n",
      "\n",
      "5. (['woman', 'playing', 'violin'], ['young', 'lady', 'enjoys', 'listening', 'guitar']) \n",
      "\n",
      "6. (['john', 'went', 'horse', 'back', 'riding', 'dawn', 'whole', 'group', 'friends'], ['sunrise', 'dawn', 'magnificent', 'view', 'take', 'wake', 'early', 'enough']) \n",
      "\n",
      "Similarities:\n",
      "\n",
      "1. 0.0\n",
      "2. 0.25\n",
      "3. 0.5\n",
      "4. 0.5\n",
      "5. 0.0\n",
      "6. 0.0625\n",
      "\n",
      "Pearson correlation: 0.09894548898363074\n"
     ]
    }
   ],
   "source": [
    "As the correlation coefficient shows, it gets a worse result. Consequently, the utilization of stopwords and other elements can improve the results in these cases as they provide a structure that helps to compare sentences. Nevertheless, as it was mentioned above, other features should be analyzed to get a higher *Pearson Correlation Coefficient*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the correlation coefficient shows, it gets a worse result. Consequently, the utilization of stopwords and other elements can improve the results in these cases as they provide a structure that helps to compare sentences. Nevertheless, as it was mentioned above, other features should be analyzed to get a higher *Pearson Correlation Coefficient*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
