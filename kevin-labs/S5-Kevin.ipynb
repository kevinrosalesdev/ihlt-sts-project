{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHLT - Lab 5\n",
    "\n",
    "- Given the following (lemma, category) pairs:\n",
    "\n",
    "`(’the’,’DT’), (’man’,’NN’), (’swim’,’VB’), (’with’, ’PR’), (’a’, ’DT’),\n",
    "(’girl’,’NN’), (’and’, ’CC’), (’a’, ’DT’), (’boy’, ’NN’), (’whilst’, ’PR’),\n",
    "(’the’, ’DT’), (’woman’, ’NN’), (’walk’, ’VB’)`\n",
    "\n",
    "- For each pair, when possible, print their most frequent WordNet synset, their corresponding least common subsumer (LCS) and their similarity value, using the following functions:\n",
    "\n",
    "    - Path Similarity\n",
    "\n",
    "    - Leacock-Chodorow Similarity\n",
    "\n",
    "    - Wu-Palmer Similarity\n",
    "\n",
    "    - Lin Similarity\n",
    "\n",
    "Normalize similarity values when necessary. What similarity seems better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet_ic, wordnet as wn\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "Synsets are created by taking the lemmas and the categories from the given pairs. Returned synsets are sorted by its frequency, so the first one is the most frequent synset for that pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma 'the' cannot be a synset because its category is DT.\n",
      "\n",
      "Appending most frequent synset for lemma 'man' (category: 'NN'):\n",
      "Synset('man.n.01')\n",
      "\n",
      "Appending most frequent synset for lemma 'swim' (category: 'VB'):\n",
      "Synset('swim.v.01')\n",
      "\n",
      "Lemma 'with' cannot be a synset because its category is PR.\n",
      "\n",
      "Lemma 'a' cannot be a synset because its category is DT.\n",
      "\n",
      "Appending most frequent synset for lemma 'girl' (category: 'NN'):\n",
      "Synset('girl.n.01')\n",
      "\n",
      "Lemma 'and' cannot be a synset because its category is CC.\n",
      "\n",
      "Lemma 'a' cannot be a synset because its category is DT.\n",
      "\n",
      "Appending most frequent synset for lemma 'boy' (category: 'NN'):\n",
      "Synset('male_child.n.01')\n",
      "\n",
      "Lemma 'whilst' cannot be a synset because its category is PR.\n",
      "\n",
      "Lemma 'the' cannot be a synset because its category is DT.\n",
      "\n",
      "Appending most frequent synset for lemma 'woman' (category: 'NN'):\n",
      "Synset('woman.n.01')\n",
      "\n",
      "Appending most frequent synset for lemma 'walk' (category: 'VB'):\n",
      "Synset('walk.v.01')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pairs = [('the','DT'), ('man','NN'), ('swim','VB'), ('with', 'PR'), ('a', 'DT'),\n",
    "         ('girl','NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'),\n",
    "         ('the', 'DT'), ('woman', 'NN'), ('walk', 'VB')]\n",
    "\n",
    "synsets = list()\n",
    "for lemma, category in pairs:\n",
    "    try:\n",
    "        synset = wn.synsets(lemma, category[0].lower())[0]\n",
    "        print(\"Appending most frequent synset for lemma '\" + lemma + \"' (category: '\" + category + \"'):\\n\" + str(synset) + \"\\n\")\n",
    "        synsets.append(synset)\n",
    "    except:\n",
    "        print(\"Lemma '\" + lemma + \"' cannot be a synset because its category is \" + category + \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pairs of most frequent WordNet synsets\n",
    "In order to compare the most frequent WordNet synsets between them, only all the possible combinations between them will be obtained (taking into consideration the following properties: `LCS(a,b) = LCS (b,a)`, `sim(a,b) = sim(b,a)`, `LCS(a,a) = a` and `sim(a,a) = max(sim)`) to optimize the rest of sections of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs of most frequent WordNet synsets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Synset('man.n.01'), Synset('swim.v.01')),\n",
       " (Synset('man.n.01'), Synset('girl.n.01')),\n",
       " (Synset('man.n.01'), Synset('male_child.n.01')),\n",
       " (Synset('man.n.01'), Synset('woman.n.01')),\n",
       " (Synset('man.n.01'), Synset('walk.v.01')),\n",
       " (Synset('swim.v.01'), Synset('girl.n.01')),\n",
       " (Synset('swim.v.01'), Synset('male_child.n.01')),\n",
       " (Synset('swim.v.01'), Synset('woman.n.01')),\n",
       " (Synset('swim.v.01'), Synset('walk.v.01')),\n",
       " (Synset('girl.n.01'), Synset('male_child.n.01')),\n",
       " (Synset('girl.n.01'), Synset('woman.n.01')),\n",
       " (Synset('girl.n.01'), Synset('walk.v.01')),\n",
       " (Synset('male_child.n.01'), Synset('woman.n.01')),\n",
       " (Synset('male_child.n.01'), Synset('walk.v.01')),\n",
       " (Synset('woman.n.01'), Synset('walk.v.01'))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_synset = list(itertools.combinations(synsets, 2))\n",
    "print(\"Pairs of most frequent WordNet synsets:\")\n",
    "mf_synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Least Common Subsumer (LCS)\n",
    "To find the LCS of each pair of synsets, their lexical relation tree must be computed. After that, the common synset whose path to the root is farther will be the LCS (*i.e.* the lowest common hypernym). In this section, the `nltk` function `synset_1.lowest_common_hypernyms(synset_2)` will be used.\n",
    "\n",
    "As it is not possible to get the LCS for synsets with different part of speech and therefore, their similarities, each time that an empty list is returned by the function, the pair will be deleted for the list of pair of synsets.\n",
    "\n",
    "Pairs of synsets composed by the same synsets have that synset as the LCS, so these pairs have not been computed (`LCS(a,a) = a`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the pair of synsets: Synset('man.n.01') vs. Synset('swim.v.01') as they are from different PoS.\n",
      "\n",
      "LCS of pair of synsets: Synset('man.n.01') vs. Synset('girl.n.01'): Synset('adult.n.01')\n",
      "\n",
      "LCS of pair of synsets: Synset('man.n.01') vs. Synset('male_child.n.01'): Synset('male.n.02')\n",
      "\n",
      "LCS of pair of synsets: Synset('man.n.01') vs. Synset('woman.n.01'): Synset('adult.n.01')\n",
      "\n",
      "Deleting the pair of synsets: Synset('man.n.01') vs. Synset('walk.v.01') as they are from different PoS.\n",
      "\n",
      "Deleting the pair of synsets: Synset('swim.v.01') vs. Synset('girl.n.01') as they are from different PoS.\n",
      "\n",
      "Deleting the pair of synsets: Synset('swim.v.01') vs. Synset('male_child.n.01') as they are from different PoS.\n",
      "\n",
      "Deleting the pair of synsets: Synset('swim.v.01') vs. Synset('woman.n.01') as they are from different PoS.\n",
      "\n",
      "LCS of pair of synsets: Synset('swim.v.01') vs. Synset('walk.v.01'): Synset('travel.v.01')\n",
      "\n",
      "LCS of pair of synsets: Synset('girl.n.01') vs. Synset('male_child.n.01'): Synset('person.n.01')\n",
      "\n",
      "LCS of pair of synsets: Synset('girl.n.01') vs. Synset('woman.n.01'): Synset('woman.n.01')\n",
      "\n",
      "Deleting the pair of synsets: Synset('girl.n.01') vs. Synset('walk.v.01') as they are from different PoS.\n",
      "\n",
      "LCS of pair of synsets: Synset('male_child.n.01') vs. Synset('woman.n.01'): Synset('person.n.01')\n",
      "\n",
      "Deleting the pair of synsets: Synset('male_child.n.01') vs. Synset('walk.v.01') as they are from different PoS.\n",
      "\n",
      "Deleting the pair of synsets: Synset('woman.n.01') vs. Synset('walk.v.01') as they are from different PoS.\n",
      "\n",
      "Final pairs of synsets to compare:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Synset('man.n.01'), Synset('girl.n.01')),\n",
       " (Synset('man.n.01'), Synset('male_child.n.01')),\n",
       " (Synset('man.n.01'), Synset('woman.n.01')),\n",
       " (Synset('swim.v.01'), Synset('walk.v.01')),\n",
       " (Synset('girl.n.01'), Synset('male_child.n.01')),\n",
       " (Synset('girl.n.01'), Synset('woman.n.01')),\n",
       " (Synset('male_child.n.01'), Synset('woman.n.01'))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_i = []\n",
    "\n",
    "for index, pair in enumerate(mf_synset):\n",
    "    lcs = pair[0].lowest_common_hypernyms(pair[1])\n",
    "    if lcs:\n",
    "        print(\"LCS of pair of synsets: \" \n",
    "              + str(pair[0]) + \" vs. \" \n",
    "              + str(pair[1]) + \": \" + \n",
    "              str(lcs[0]) + \"\\n\")\n",
    "    else:\n",
    "        print(\"Deleting the pair of synsets: \"\n",
    "              + str(pair[0]) + \" vs. \" \n",
    "              + str(pair[1]) + \" as they are from different PoS.\\n\")\n",
    "        del_i.append(index)\n",
    "        \n",
    "mf_synset = [pair for index, pair in enumerate(mf_synset) if index not in del_i]\n",
    "\n",
    "print(\"Final pairs of synsets to compare:\")\n",
    "mf_synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Similarity Values\n",
    "In this section, several similarity functions will be used to measure the level of equivalence between each pair of synsets.\n",
    "\n",
    "It must be taken into account that a synset compared to itself is supposed to have the maximum similarity, so  these pairs have not been included in the most frequent pairs of synsets. Moreover, similarity between synsets from different PoS cannot be compared using these similarities, so they are supposed to have a similarity value of `0` (these pairs have not been included in the most frequent pairs of synsets too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity values between Synset('man.n.01') and Synset('girl.n.01'):\n",
      "- Path Similarity: 0.25\n",
      "- Leacock-Chodorow Similarity: 2.251\n",
      "- Wu-Palmer Similarity: 0.632\n",
      "- Lin Similarity: 0.714\n",
      "\n",
      "Similarity values between Synset('man.n.01') and Synset('male_child.n.01'):\n",
      "- Path Similarity: 0.333\n",
      "- Leacock-Chodorow Similarity: 2.539\n",
      "- Wu-Palmer Similarity: 0.667\n",
      "- Lin Similarity: 0.729\n",
      "\n",
      "Similarity values between Synset('man.n.01') and Synset('woman.n.01'):\n",
      "- Path Similarity: 0.333\n",
      "- Leacock-Chodorow Similarity: 2.539\n",
      "- Wu-Palmer Similarity: 0.667\n",
      "- Lin Similarity: 0.787\n",
      "\n",
      "Similarity values between Synset('swim.v.01') and Synset('walk.v.01'):\n",
      "- Path Similarity: 0.333\n",
      "- Leacock-Chodorow Similarity: 2.159\n",
      "- Wu-Palmer Similarity: 0.333\n",
      "- Lin Similarity: 0.491\n",
      "\n",
      "Similarity values between Synset('girl.n.01') and Synset('male_child.n.01'):\n",
      "- Path Similarity: 0.167\n",
      "- Leacock-Chodorow Similarity: 1.846\n",
      "- Wu-Palmer Similarity: 0.632\n",
      "- Lin Similarity: 0.293\n",
      "\n",
      "Similarity values between Synset('girl.n.01') and Synset('woman.n.01'):\n",
      "- Path Similarity: 0.5\n",
      "- Leacock-Chodorow Similarity: 2.944\n",
      "- Wu-Palmer Similarity: 0.632\n",
      "- Lin Similarity: 0.907\n",
      "\n",
      "Similarity values between Synset('male_child.n.01') and Synset('woman.n.01'):\n",
      "- Path Similarity: 0.2\n",
      "- Leacock-Chodorow Similarity: 2.028\n",
      "- Wu-Palmer Similarity: 0.667\n",
      "- Lin Similarity: 0.318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "lch = list()\n",
    "for pair in mf_synset:\n",
    "    lch_value = round(pair[0].lch_similarity(pair[1]), 3)\n",
    "    lch.append(lch_value)\n",
    "    print(\"Similarity values between \" + str(pair[0]) + \" and \" + str(pair[1]) + \":\") \n",
    "    print(\"- Path Similarity: \" + str(round(pair[0].path_similarity(pair[1]), 3)))\n",
    "    print(\"- Leacock-Chodorow Similarity: \" + str(lch_value))\n",
    "    print(\"- Wu-Palmer Similarity: \" + str(round(pair[0].wup_similarity(pair[1]), 3)))\n",
    "    print(\"- Lin Similarity: \" + str(round(pair[0].lin_similarity(pair[1], brown_ic), 3)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the similarities are given within the interval [0, 1], except *Leacock-Chodorow Similarity*. Since it has not got a specific maximum value and in order to normalize their values, each of these similarities will be divided by the maximum *Leacock-Chodorow Similarity* for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity values between Synset('man.n.01') and Synset('girl.n.01'):\n",
      "- Leacock-Chodorow Similarity: 0.619\n",
      "\n",
      "Similarity values between Synset('man.n.01') and Synset('male_child.n.01'):\n",
      "- Leacock-Chodorow Similarity: 0.698\n",
      "\n",
      "Similarity values between Synset('man.n.01') and Synset('woman.n.01'):\n",
      "- Leacock-Chodorow Similarity: 0.698\n",
      "\n",
      "Similarity values between Synset('swim.v.01') and Synset('walk.v.01'):\n",
      "- Leacock-Chodorow Similarity: 0.663\n",
      "\n",
      "Similarity values between Synset('girl.n.01') and Synset('male_child.n.01'):\n",
      "- Leacock-Chodorow Similarity: 0.507\n",
      "\n",
      "Similarity values between Synset('girl.n.01') and Synset('woman.n.01'):\n",
      "- Leacock-Chodorow Similarity: 0.809\n",
      "\n",
      "Similarity values between Synset('male_child.n.01') and Synset('woman.n.01'):\n",
      "- Leacock-Chodorow Similarity: 0.558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, pair in enumerate(mf_synset):\n",
    "    print(\"Similarity values between \" + str(pair[0]) + \" and \" + str(pair[1]) + \":\") \n",
    "    print(\"- Leacock-Chodorow Similarity: \" \n",
    "          + str(round(lch[index]/pair[0].lch_similarity(pair[0]), 3)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**What similarity seems better?**\n",
    "\n",
    "The similarity that performs better depends on the belief about the level of similarity of each pair of synsets.\n",
    "Considering the following ranking about similarities:\n",
    "\n",
    "1, 2) Man vs Male child [2] / Girl vs Woman [6] (Same gender)\n",
    "\n",
    "3, 4) Girl vs Male child [5] / Man vs Woman [3] (Same age)\n",
    "\n",
    "5, 6) Man vs girl [1] / Male child vs Woman [7] (Human being)\n",
    "\n",
    "7) Swim vs Walk [4] (Movement)\n",
    "\n",
    "And taking into consideration that the order of each similarity* (as it was shown in the previous section) using these algorithms is:\n",
    "- Path Similarity: [6, 2/3/4, 1, 7, 5]\n",
    "    - It returns `Swim vs. Walk` as similar as than `Man vs Woman` or `Man vs Male child`.\n",
    "    - Small variance between similarities (Only from 0.167 to 0.5)\n",
    "- Leacock-Chodorow Similarity: [6, 2/3, 4, 1, 7, 5]\n",
    "    - It returns `Man vs. Male child` with same similarity than `Man vs. Woman`\n",
    "    - Small variance between similarities after normalization (Only from 0.507 to 0.809)\n",
    "- Wu-Palmer Similarity: [2/3/7, 1/5/6, 4]\n",
    "    - Small variance between similarities (From 0.333 to 0.667).\n",
    "        - Only 3 sets of different similarities can be obtained.\n",
    "        - First 2 sets have nearly the same similarities (0.667 vs. 0.632).\n",
    "- Lin Similarity: [6, 3, 2, 1, 4, 7, 5]\n",
    "    - Except for `Male child vs. Woman` and `Girl vs. Male child` cases, the rest of similarities perform in a sensible way.\n",
    "    - Good variability of similarities (and good distance between them).\n",
    "    \n",
    "**The quantity of similarity provided by each algorithm has been taken into account too.*\n",
    "    \n",
    "**Lin Similarity** seems to perform better. The underlying reason behind is the computation on this similarity as it takes into consideration the LCS instead of the Shortest Path Length (SPL) as *Path Similarity* and *Leacock-Chodorow Similarity* do and the Information Content (frequencies in *wordnet_ic* corpus). This is the reason of the good variability of its similarities with respect to the other similarities algorithms.\n",
    "\n",
    "The formula that this similarity computes is the following:\n",
    "\n",
    "$ Sim(s_1, s_2) = \\frac{2*IC(LCS(s1,s2))}{IC(s1)+IC(s2)} $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}