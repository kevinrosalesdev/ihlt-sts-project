{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IHLT - Lab 7 \n",
    "1. Read all pairs of sentences of the trial set within the evaluation framework of the project.\n",
    "2. Compute their similarities by considering the following approach:\n",
    "    - words plus NEs and Jaccard coefficient (`word_and_NEs=['John Smith', 'is', 'working']`)\n",
    "3. Show the results.\n",
    "4. Do you think it could be relevant to use NEs to compute the similarity between two sentences? Justify the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "As it has been done in other lab sessions, all pairs of sentences of the trial set are read and stored in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ('The bird is bathing in the sink.', 'Birdie is washing itself in the water basin.')\n",
      "2. ('In May 2010, the troops attempted to invade Kabul.', 'The US army invaded Kabul on May 7th last year, 2010.')\n",
      "3. ('John said he is considered a witness but not a suspect.', '\"He is not a suspect anymore.\" John said.')\n",
      "4. ('They flew out of the nest in groups.', 'They flew into the nest together.')\n",
      "5. ('The woman is playing the violin.', 'The young lady enjoys listening to the guitar.')\n",
      "6. ('John went horse back riding at dawn with a whole group of friends.', 'Sunrise at dawn is a magnificent view to take in if you wake up early enough for it.')\n"
     ]
    }
   ],
   "source": [
    "pairs = list()\n",
    "with open('trial/STS.input.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = nltk.TabTokenizer().tokenize(line.strip())\n",
    "        pairs.append((line[1], line[2]))\n",
    "        \n",
    "for index, pair in enumerate(pairs):\n",
    "    print(str(index + 1) + \".\", pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word + NEs approach\n",
    "In order to get the *Jaccard Coefficient* between each pair of sentences, words + NEs will be obtained for each sample this time. The NERC will be evaluated using NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ([('The', 'DT'), ('bird', 'NN'), ('is', 'VBZ'), ('bathing', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('sink', 'NN'), ('.', '.')], [('Birdie', 'NNP'), ('is', 'VBZ'), ('washing', 'VBG'), ('itself', 'PRP'), ('in', 'IN'), ('the', 'DT'), ('water', 'NN'), ('basin', 'NN'), ('.', '.')]) \n",
      "\n",
      "2. ([('In', 'IN'), ('May', 'NNP'), ('2010', 'CD'), (',', ','), ('the', 'DT'), ('troops', 'NNS'), ('attempted', 'VBD'), ('to', 'TO'), ('invade', 'VB'), ('Kabul', 'NNP'), ('.', '.')], [('The', 'DT'), ('US', 'NNP'), ('army', 'NN'), ('invaded', 'VBD'), ('Kabul', 'NNP'), ('on', 'IN'), ('May', 'NNP'), ('7th', 'CD'), ('last', 'JJ'), ('year', 'NN'), (',', ','), ('2010', 'CD'), ('.', '.')]) \n",
      "\n",
      "3. ([('John', 'NNP'), ('said', 'VBD'), ('he', 'PRP'), ('is', 'VBZ'), ('considered', 'VBN'), ('a', 'DT'), ('witness', 'NN'), ('but', 'CC'), ('not', 'RB'), ('a', 'DT'), ('suspect', 'NN'), ('.', '.')], [('``', '``'), ('He', 'PRP'), ('is', 'VBZ'), ('not', 'RB'), ('a', 'DT'), ('suspect', 'NN'), ('anymore', 'RB'), ('.', '.'), (\"''\", \"''\"), ('John', 'NNP'), ('said', 'VBD'), ('.', '.')]) \n",
      "\n",
      "4. ([('They', 'PRP'), ('flew', 'VBD'), ('out', 'IN'), ('of', 'IN'), ('the', 'DT'), ('nest', 'JJS'), ('in', 'IN'), ('groups', 'NNS'), ('.', '.')], [('They', 'PRP'), ('flew', 'VBD'), ('into', 'IN'), ('the', 'DT'), ('nest', 'JJS'), ('together', 'RB'), ('.', '.')]) \n",
      "\n",
      "5. ([('The', 'DT'), ('woman', 'NN'), ('is', 'VBZ'), ('playing', 'VBG'), ('the', 'DT'), ('violin', 'NN'), ('.', '.')], [('The', 'DT'), ('young', 'JJ'), ('lady', 'NN'), ('enjoys', 'VBZ'), ('listening', 'VBG'), ('to', 'TO'), ('the', 'DT'), ('guitar', 'NN'), ('.', '.')]) \n",
      "\n",
      "6. ([('John', 'NNP'), ('went', 'VBD'), ('horse', 'NN'), ('back', 'RB'), ('riding', 'VBG'), ('at', 'IN'), ('dawn', 'NN'), ('with', 'IN'), ('a', 'DT'), ('whole', 'JJ'), ('group', 'NN'), ('of', 'IN'), ('friends', 'NNS'), ('.', '.')], [('Sunrise', 'NN'), ('at', 'IN'), ('dawn', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('magnificent', 'JJ'), ('view', 'NN'), ('to', 'TO'), ('take', 'VB'), ('in', 'IN'), ('if', 'IN'), ('you', 'PRP'), ('wake', 'VBP'), ('up', 'RP'), ('early', 'RB'), ('enough', 'RB'), ('for', 'IN'), ('it', 'PRP'), ('.', '.')]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pairs = [(pos_tag(word_tokenize(p[0])), pos_tag(word_tokenize(p[1]))) for p in pairs]\n",
    "\n",
    "for index, pair in enumerate(pairs):\n",
    "    print(str(index + 1) + \".\", pair, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the NLTK's NERC, the option `binary=True` will be used in order to just recognize named entities, without taking into consideration the classification of three NEs classes (PERSON, LOCATION, ORGANIZATION). Moreover, the function `tree2conlltags(ne_chunk_res)` will be utilized in order to iterate and get the NEs.\n",
    "\n",
    "The function `transform_sentence(ne_chunk_res)` will iterate over the tree using `tree2conlltags(ne_chunk_res)` and will return the proposed approach (Words + NEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sentence(ne_chunk_res):\n",
    "    conlltags = nltk.chunk.tree2conlltags(ne_chunk_res)\n",
    "    transformed_sentence = []\n",
    "    index = 0\n",
    "    while index < len(conlltags):\n",
    "        if conlltags[index][2] == 'B-NE':\n",
    "            ne = conlltags[index][0]\n",
    "            for consecutive_index in range(index+1, len(conlltags)):\n",
    "                if conlltags[consecutive_index][2] == 'I-NE':\n",
    "                    ne += \" \" + conlltags[consecutive_index][0]\n",
    "                else:\n",
    "                    break\n",
    "            transformed_sentence.append(ne)\n",
    "            index = consecutive_index\n",
    "        else:\n",
    "            transformed_sentence.append(conlltags[index][0])\n",
    "            index += 1\n",
    "    return transformed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (['The', 'bird', 'is', 'bathing', 'in', 'the', 'sink', '.'], ['Birdie', 'is', 'washing', 'itself', 'in', 'the', 'water', 'basin', '.']) \n",
      "\n",
      "2. (['In', 'May', '2010', ',', 'the', 'troops', 'attempted', 'to', 'invade', 'Kabul', '.'], ['The', 'US', 'army', 'invaded', 'Kabul', 'on', 'May', '7th', 'last', 'year', ',', '2010', '.']) \n",
      "\n",
      "3. (['John', 'said', 'he', 'is', 'considered', 'a', 'witness', 'but', 'not', 'a', 'suspect', '.'], ['``', 'He', 'is', 'not', 'a', 'suspect', 'anymore', '.', \"''\", 'John', 'said', '.']) \n",
      "\n",
      "4. (['They', 'flew', 'out', 'of', 'the', 'nest', 'in', 'groups', '.'], ['They', 'flew', 'into', 'the', 'nest', 'together', '.']) \n",
      "\n",
      "5. (['The', 'woman', 'is', 'playing', 'the', 'violin', '.'], ['The', 'young', 'lady', 'enjoys', 'listening', 'to', 'the', 'guitar', '.']) \n",
      "\n",
      "6. (['John', 'went', 'horse', 'back', 'riding', 'at', 'dawn', 'with', 'a', 'whole', 'group', 'of', 'friends', '.'], ['Sunrise', 'at', 'dawn', 'is', 'a', 'magnificent', 'view', 'to', 'take', 'in', 'if', 'you', 'wake', 'up', 'early', 'enough', 'for', 'it', '.']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_and_NEs = [(transform_sentence(ne_chunk(pair[0], binary=True)), \n",
    "                 transform_sentence(ne_chunk(pair[1], binary=True))) \n",
    "                for pair in pairs]\n",
    "\n",
    "for index, pair in enumerate(word_and_NEs):\n",
    "    print(str(index + 1) + \".\", pair, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice from the output that this approach with the *trial set* would be the same that the approach using only words. The reason behind this is that the NEs have a maximum length of 1 in these pairs (*e.g.* 'Kabul', 'Birdie'...).**\n",
    "\n",
    "Therefore, as the sets are composed of the same elements used in other sessions, the similarity and the *Pearson Correlation Coefficient* will be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Similarities and *Jaccard Coefficient*\n",
    "\n",
    "As we have done in other lab sessions, the *Jaccard Coefficient* is used in order to compute the similarity between pairs of sentences. In this case, it is used the combination of their words and NEs (with all NEs with a maximum length of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities (considering Words + NEs):\n",
      "\n",
      "1. 0.3076923076923077\n",
      "2. 0.26315789473684215\n",
      "3. 0.4666666666666667\n",
      "4. 0.4545454545454546\n",
      "5. 0.23076923076923073\n",
      "6. 0.13793103448275867\n"
     ]
    }
   ],
   "source": [
    "similarities = [1 - jaccard_distance(set(p[0]), set(p[1])) for p in word_and_NEs]\n",
    "\n",
    "print(\"Similarities (considering Words + NEs):\\n\")\n",
    "for index, similarity in enumerate(similarities, 1):\n",
    "    print(str(index) + \".\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it has been done in the other lab sessions, the similarities will be compared to the Gold Standard using the *Pearson Correlation Coefficient* too.\n",
    "\n",
    "According to `00-readme.txt`, the similarity between two sentences that are completely equivalent should be 1/1 (or 5/5) and the similarity between two sentences that are on different topics should be 0/1 (or 0/5). For that reason, the reference similarities should be `[1.0, 0.8, 0.6, 0.4, 0.2, 0]` or its proportional values `[5, 4, 3, 2, 1, 0]`.\n",
    "\n",
    "The values in the gold standard file STS.gs.txt are reversed, so they will be read and then inverted in order to get them correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold standard: [5, 4, 3, 2, 1, 0]\n",
      "Pearson correlation (words + NEs): 0.3962389776119232\n"
     ]
    }
   ],
   "source": [
    "gs = list()\n",
    "with open('trial/STS.gs.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = nltk.TabTokenizer().tokenize(line.strip())\n",
    "        gs.append(int(line[1]))\n",
    "\n",
    "gs.reverse()\n",
    "print(\"Gold standard:\", gs)\n",
    "print(\"Pearson correlation (words + NEs):\", pearsonr(gs, similarities)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you think it could be relevant to use NEs to compute the similarity between two sentences? Justify the answer.**\n",
    "\n",
    "As it has been explained, the NEs in the *trial set* have a maximum length of one word. Consequently, the same similarities and *Pearson Correlation Coefficient* are obtained.\n",
    "\n",
    "To answer this question, 5 pairs of sentences from the *test set* of the project (`STS.input.MSRpar.txt`) will be selected in order to use this approach (words + NEs) and compare correctly its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list()\n",
    "with open('test-gold/STS.input.MSRpar.txt','r') as f:\n",
    "    lines = f.readlines()[:5]\n",
    "    for line in lines:\n",
    "        line = nltk.TabTokenizer().tokenize(line.strip())\n",
    "        pairs.append((line[0], line[1]))\n",
    "\n",
    "word = [(word_tokenize(p[0]), word_tokenize(p[1])) for p in pairs]\n",
    "\n",
    "pairs = [(pos_tag(p[0]), pos_tag(p[1])) for p in word]\n",
    "word_and_NEs = [(transform_sentence(ne_chunk(pair[0], binary=True)), \n",
    "                 transform_sentence(ne_chunk(pair[1], binary=True))) \n",
    "                for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words\n",
      "1. (['The', 'problem', 'likely', 'will', 'mean', 'corrective', 'changes', 'before', 'the', 'shuttle', 'fleet', 'starts', 'flying', 'again', '.'], ['He', 'said', 'the', 'problem', 'needs', 'to', 'be', 'corrected', 'before', 'the', 'space', 'shuttle', 'fleet', 'is', 'cleared', 'to', 'fly', 'again', '.']) \n",
      "\n",
      "2. (['The', 'technology-laced', 'Nasdaq', 'Composite', 'Index', '.IXIC', 'inched', 'down', '1', 'point', ',', 'or', '0.11', 'percent', ',', 'to', '1,650', '.'], ['The', 'broad', 'Standard', '&', 'Poor', \"'s\", '500', 'Index', '.SPX', 'inched', 'up', '3', 'points', ',', 'or', '0.32', 'percent', ',', 'to', '970', '.']) \n",
      "\n",
      "3. (['``', 'It', \"'s\", 'a', 'huge', 'black', 'eye', ',', \"''\", 'said', 'publisher', 'Arthur', 'Ochs', 'Sulzberger', 'Jr.', ',', 'whose', 'family', 'has', 'controlled', 'the', 'paper', 'since', '1896', '.'], ['``', 'It', \"'s\", 'a', 'huge', 'black', 'eye', ',', \"''\", 'Arthur', 'Sulzberger', ',', 'the', 'newspaper', \"'s\", 'publisher', ',', 'said', 'of', 'the', 'scandal', '.']) \n",
      "\n",
      "4. (['SEC', 'Chairman', 'William', 'Donaldson', 'said', 'there', 'is', 'a', '``', 'building', 'confidence', 'out', 'there', 'that', 'the', 'cop', 'is', 'on', 'the', 'beat', '.', \"''\"], ['``', 'I', 'think', 'there', \"'s\", 'a', 'building', 'confidence', 'that', 'the', 'cop', 'is', 'on', 'the', 'beat', '.', \"''\"]) \n",
      "\n",
      "5. (['Vivendi', 'shares', 'closed', '1.9', 'percent', 'at', '15.80', 'euros', 'in', 'Paris', 'after', 'falling', '3.6', 'percent', 'on', 'Monday', '.'], ['In', 'New', 'York', ',', 'Vivendi', 'shares', 'were', '1.4', 'percent', 'down', 'at', '$', '18.29', '.']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Words\")\n",
    "for index, pair in enumerate(word):\n",
    "    print(str(index + 1) + \".\", pair, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words + NEs\n",
      "1. (['The', 'problem', 'likely', 'will', 'mean', 'corrective', 'changes', 'before', 'the', 'shuttle', 'fleet', 'starts', 'flying', 'again', '.'], ['He', 'said', 'the', 'problem', 'needs', 'to', 'be', 'corrected', 'before', 'the', 'space', 'shuttle', 'fleet', 'is', 'cleared', 'to', 'fly', 'again', '.']) \n",
      "\n",
      "2. (['The', 'technology-laced', 'Nasdaq Composite Index', '.IXIC', 'inched', 'down', '1', 'point', ',', 'or', '0.11', 'percent', ',', 'to', '1,650', '.'], ['The', 'broad', 'Standard', '&', 'Poor', \"'s\", '500', 'Index', '.SPX', 'inched', 'up', '3', 'points', ',', 'or', '0.32', 'percent', ',', 'to', '970', '.']) \n",
      "\n",
      "3. (['``', 'It', \"'s\", 'a', 'huge', 'black', 'eye', ',', \"''\", 'said', 'publisher', 'Arthur Ochs Sulzberger', 'Jr.', ',', 'whose', 'family', 'has', 'controlled', 'the', 'paper', 'since', '1896', '.'], ['``', 'It', \"'s\", 'a', 'huge', 'black', 'eye', ',', \"''\", 'Arthur Sulzberger', ',', 'the', 'newspaper', \"'s\", 'publisher', ',', 'said', 'of', 'the', 'scandal', '.']) \n",
      "\n",
      "4. (['SEC', 'Chairman', 'William Donaldson', 'said', 'there', 'is', 'a', '``', 'building', 'confidence', 'out', 'there', 'that', 'the', 'cop', 'is', 'on', 'the', 'beat', '.', \"''\"], ['``', 'I', 'think', 'there', \"'s\", 'a', 'building', 'confidence', 'that', 'the', 'cop', 'is', 'on', 'the', 'beat', '.', \"''\"]) \n",
      "\n",
      "5. (['Vivendi', 'shares', 'closed', '1.9', 'percent', 'at', '15.80', 'euros', 'in', 'Paris', 'after', 'falling', '3.6', 'percent', 'on', 'Monday', '.'], ['In', 'New York', ',', 'Vivendi', 'shares', 'were', '1.4', 'percent', 'down', 'at', '$', '18.29', '.']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Words + NEs\")\n",
    "for index, pair in enumerate(word_and_NEs):\n",
    "    print(str(index + 1) + \".\", pair, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities and *Jaccard Correlation Coefficient* with this *test set*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities (considering Words) [test set]:\n",
      "\n",
      "1. 0.28\n",
      "2. 0.27586206896551724\n",
      "3. 0.5555555555555556\n",
      "4. 0.5909090909090908\n",
      "5. 0.19999999999999996\n",
      "\n",
      "Similarities (considering Words + NEs) [test set]:\n",
      "\n",
      "1. 0.28\n",
      "2. 0.25\n",
      "3. 0.5\n",
      "4. 0.6190476190476191\n",
      "5. 0.20833333333333337\n"
     ]
    }
   ],
   "source": [
    "similarities = [1 - jaccard_distance(set(p[0]), set(p[1])) for p in word]\n",
    "\n",
    "print(\"Similarities (considering Words) [test set]:\\n\")\n",
    "for index, similarity in enumerate(similarities, 1):\n",
    "    print(str(index) + \".\", similarity)\n",
    "    \n",
    "similarities_NEs = [1 - jaccard_distance(set(p[0]), set(p[1])) for p in word_and_NEs]\n",
    "\n",
    "print(\"\\nSimilarities (considering Words + NEs) [test set]:\\n\")\n",
    "for index, similarity in enumerate(similarities_NEs, 1):\n",
    "    print(str(index) + \".\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold standard: [4.4, 0.8, 3.6, 3.4, 1.4]\n",
      "Pearson correlation (words): 0.5138216407797424\n",
      "Pearson correlation (words + NEs): 0.5239147649937855\n"
     ]
    }
   ],
   "source": [
    "gs = list()\n",
    "with open('test-gold/STS.gs.MSRpar.txt','r') as f:\n",
    "    lines = f.readlines()[:5]\n",
    "    for line in lines:\n",
    "        line = nltk.TabTokenizer().tokenize(line.strip())\n",
    "        gs.append(float(line[0]))\n",
    "\n",
    "print(\"Gold standard:\", gs)\n",
    "print(\"Pearson correlation (words):\", pearsonr(gs, similarities)[0])\n",
    "print(\"Pearson correlation (words + NEs):\", pearsonr(gs, similarities_NEs)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be analyzed, the utilization of NEs can improve the *Pearson Correlation Coefficient*. Some pairs of sentences will be studied in order to infer the reason of this improvement (NEs in bold):\n",
    "\n",
    "- Second pair:\n",
    "    - The technology-laced **Nasdaq Composite Index** .IXIC inched down 1 point, or 0.11 percent, to 1,650.\t\n",
    "    - The broad Standard & Poor's 500 *Index* .SPX inched up 3 points, or 0.32 percent, to 970.\n",
    "    \n",
    "As **Nasdaq Composite Index** is a NEs, when the *Jaccard distance* is computed, it does not take into consideration the word *Index* as an equivalence between the pair of sentence. Therefore, the similarity gets a lower value and results in a value nearer to the GS.\n",
    "\n",
    "- Fourth pair:\n",
    "    - SEC Chairman **William Donaldson** said there is a \"building confidence out there that the cop is on the beat.\"\n",
    "    - \"I think there's a building confidence that the cop is on the beat.\"\n",
    "    \n",
    "As **William Donaldson** is considered as a singular element, there are less different elements between the pair of sentences. Consequently, the similarity gets a higher value and results in a value nearer to the GS.\n",
    "\n",
    "- Fifth pair:\n",
    "    - Vivendi shares closed 1.9 percent at 15.80 euros in Paris after falling 3.6 percent on Monday.\n",
    "    - In **New York**, Vivendi shares were 1.4 percent down at $18.29.\n",
    "\n",
    "In this pair, the same situation that happened with the fourth pair occurs.\n",
    "\n",
    "Nevertheless, sometimes, the use of NEs can produce worse results sometimes:\n",
    "\n",
    "- Third pair:\n",
    "    - \"It's a huge black eye,\" said publisher **Arthur Ochs Sulzberger** Jr., whose family has controlled the paper since 1896.\n",
    "    - \"It's a huge black eye,\" **Arthur Sulzberger**, the newspaper's publisher, said of the scandal.\n",
    "    \n",
    "In this case, since the entire name **Arthur Ochs Sulzberger** is not equal to the name of the second sentence **Arthur Sulzberger**, the similarity gets a lower value and more distance to the GS.\n",
    "\n",
    "In conclusion, after analyzing these examples, the use of NEs can be relevant when computing the similarity between a pair of sentences. Even taking into account samples where the results get worse (fifth pair), there are some cases where the results improve (second, fourth & fifth pair). The underlying reason behind this is the fact that some combination of words should be taken as a single word (*e.g.* New York) instead of comparing them separately. In other words, only if the entire NEs is in the other sentence, it should be taken as a similar word. \n",
    "\n",
    "On the other hand, as the number of elements inside each set of the *Jaccard Distance* is reduced (due to the transformation of sequence of words to a single NE), the variation of similarity (*i.e.* the weight of each element in the computation) is greater. Therefore, if the inclusion of NEs is taken with caution, it can be relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optional Exercise\n",
    "Enlarge the provided grammar to parse the next sentence as the image of the definition of the exercise:\n",
    "\n",
    "```python\n",
    "[(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),(\"dog\", \"NN\"),\\\n",
    " (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\"), \\\n",
    " (\"in\", \"IN\"), (\"New\", \"NNP\"), (\"York\", \"NNP\")]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  (PP at/IN (NP the/DT cat/NN))\n",
      "  (PP in/IN (NP New/NNP York/NNP)))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('S', [Tree('NP', [('the', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN')]), ('barked', 'VBD'), Tree('PP', [('at', 'IN'), Tree('NP', [('the', 'DT'), ('cat', 'NN')])]), Tree('PP', [('in', 'IN'), Tree('NP', [('New', 'NNP'), ('York', 'NNP')])])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),(\"dog\", \"NN\"),\\\n",
    "            (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\"), \\\n",
    "            (\"in\", \"IN\"), (\"New\", \"NNP\"), (\"York\", \"NNP\")]\n",
    "\n",
    "# grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "grammar = \"\"\"\n",
    "          NP: {<DT>?<JJ>*<NN>|<NNP>+}\n",
    "          PP: {<IN><NP>}\n",
    "          \"\"\" \n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(sentence)\n",
    "\n",
    "print(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be observed, the grammar has changed from this:\n",
    "\n",
    "`NP: {<DT>?<JJ>*<NN>}`\n",
    "\n",
    "To a grammar composed by:\n",
    "\n",
    "`NP: {<DT>?<JJ>*<NN>|<NNP>+}`, where it is admitted that a NP can be composed by a sequence of proper singular noun (NNP) instead of by a single singular or mass noun (NN) (therefore, New York is considered a NP too).\n",
    "\n",
    "`PP: {<IN><NP>}`, where it is defined that a PP is a combination of a preposition or subordinating conjunction (IN) and the NP declared before (*e.g.* (at, the cat) or (in, New York)). \n",
    "\n",
    "Notice that the order of this composition (NP & PP and not PP & NP) is important. It must be taken into consideration that this enlargement has been made trying to affect as little as possible sentences out of this example.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
